{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from functions.functions_image_training import *\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mainfolder = '/Users/carsonlam/vp/quality_confirmed/'\n",
    "rejects = '/Users/carsonlam/vp/rejects/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dict, cat_list = classifier_folder_to_jpg_dict_list(mainfolder,rejects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_tuples = cat_list_to_list_of_tuples(img_dict, cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]] (6, 450, 450, 3)\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]] (6, 450, 450, 3)\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]] (6, 450, 450, 3)\n",
      "DONE, ran for 0.06m\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "############### INPUTS: including bacth size, list of tuples and image dictionary###########################\n",
    "total_num = len(list_of_tuples)\n",
    "classes = len(img_dict)\n",
    "batch_size = 6\n",
    "num_steps = int(total_num / batch_size)\n",
    "single_input_shape = (450,450,3)\n",
    "target_height,target_width,new_depth = single_input_shape\n",
    "epochs = 1\n",
    "################ TENSOR FLOW #########################################\n",
    "### TF variables #####################################################\n",
    "tensor_image = tf.placeholder(\"uint8\", [None, None, 3])\n",
    "\n",
    "############ Manipulations to tensors in TF variables ########################\n",
    "#### Resizing tesors #################################################################\n",
    "resized_image = tf.image.resize_images(tensor_image, target_height, target_width)\n",
    "\n",
    "######## Manipulations to resized tensors in Resizing tensors ####################\n",
    "lrflip_resized = tf.image.flip_left_right(resized_image)\n",
    "udflip_resized = tf.image.flip_up_down(resized_image)\n",
    "\n",
    "######## output count = 6\n",
    "######## initialization class for session running ########################\n",
    "model = tf.initialize_all_variables()\n",
    "########################################################################\n",
    "\n",
    "########## FOR TESTING ONLY ############################################\n",
    "num_steps = 2\n",
    "\n",
    "\n",
    "########## TRAINING LOOP #####################################################\n",
    "with tf.Session() as session: \n",
    "    \n",
    "    session.run(model)\n",
    "    \n",
    "########## NUMBER OF EPOCHS ##################################################\n",
    "    for epoch in range(epochs):    \n",
    "    ########## SHUFFLE TRAINING DATA BETWEEN EPOCHS #############################    \n",
    "        random.shuffle(list_of_tuples)\n",
    "    ########## ONE EPOCH #####################################################\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (total_num)\n",
    "            start = offset\n",
    "            end = offset + batch_size\n",
    "            if total_num - end < batch_size:\n",
    "                end += (total_num % batch_size)\n",
    "\n",
    "    ######## INITIALIZE TRAINING BATCH ########################################################\n",
    "\n",
    "            training_labels = np.zeros((batch_size,classes))\n",
    "            training_tensors = np.zeros((batch_size,*single_input_shape))\n",
    "\n",
    "    ####### USE 'start' and 'end' to build one BATCH #####################################\n",
    "    ####### HERE ################################################################\n",
    "            \n",
    "            for j in range(start,end):\n",
    "                \n",
    "                ############ jpg to numpy at list element j ##################\n",
    "                cycle_image = mpimg.imread(mainfolder + list_of_tuples[j][1])\n",
    "                # j is the id for the image in this randomized dataset \n",
    "                ############ Tensor image fitting and augmentations #####################\n",
    "                \n",
    "                croppad_image = tf.image.resize_image_with_crop_or_pad(cycle_image, target_height, target_width)\n",
    "                lrflip_croppad = tf.image.flip_left_right(croppad_image)\n",
    "                udflip_croppad = tf.image.flip_up_down(croppad_image)\n",
    "                \n",
    "                graph_output=[resized_image,lrflip_resized,udflip_resized,croppad_image,lrflip_croppad,udflip_croppad]\n",
    "                #session_output=[Resized_image,Lrflip_resized,Udflip_resized,Croppad_image,Lrflip_croppad,Udflip_croppad]\n",
    "                \n",
    "                session_output=session.run(graph_output,                                                        \n",
    "                feed_dict={tensor_image: cycle_image})\n",
    "                \n",
    "                extended_batch_size = len(graph_output)\n",
    "                i =0\n",
    "                for output in session_output:\n",
    "                    \n",
    "\n",
    "                    training_labels[i] =  list_of_tuples[j][0]\n",
    "                    training_tensors[i] = output/255 # normalize pixels \n",
    "\n",
    "                    i+=1\n",
    "########### FEED TRAINING BATCH TO NETWORK ##########################################\n",
    "########### HERE ####################################################################\n",
    "\n",
    "\n",
    "            if step > 1:\n",
    "                break \n",
    "#######################################################################################\n",
    "\n",
    "    \n",
    "end_time = timeit.default_timer()\n",
    "print('DONE, ran for %.2fm' % ((end_time - start_time) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(session_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
